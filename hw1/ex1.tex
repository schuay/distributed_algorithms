\begin{Exc}{(A2.2.v0, 5 points):}
Analyze the time complexity of the convergecast algorithm
(maximum-finding) of Section 2.2 of the textbook when (a) communication is
synchronous and (b) communication is asynchronous.
\end{Exc}

\begin{comment}
Hint: For the synchronous case, prove that during round t + 1, a processor at
height t sends a message to its parent. For the asynchronous case, prove that
by time t, a processor at height t has sent a message to its parent.
\end{comment}

% TODO: Define depth functions for each example, esp. if they differ.
% TODO: Use consistent notation for depth (d/t/D).

\newcommand{\prnt}[1]{\text{parent}(#1)}
\newcommand{\dpth}[1]{\text{depth}(#1)}

First, some notation: in this exercise, we consider a distributed system of $n$
processors $\Pi=\{p_0,\dots,p_{n-1}\}$ together with a given spanning tree of depth
$d$ rooted at processor $p_r$. The function
$\text{parent}: \Pi \rightarrow \Pi \cup \{ \text{null} \}$ returns the parent node
within the spanning tree (or null for $p_r$), while each node's depth is given by
$\text{depth}: \Pi \rightarrow \mathbb{N}$.

\begin{lemma} \label{lemma:1sync}
In a synchronous distributed system with a given rooted spanning tree executing the convergecast
algorithm, every processor at depth $t$ sends a message to its parent during round $t + 1$.
\end{lemma}

\begin{proof}
By induction. This lemma holds for $t = 0$ by the description of the algorithm,
since all leaf nodes $x$ send a message to $\prnt{x}$.

Assume the lemma holds for $t \leq n$, and consider an arbitrary node $x$ at depth
$n + 1$. By the definition of the depth function, all child nodes of $x$ must be at
a depth $\leq n$, and by the inductive hypothesis must have sent a message to
$x$ in round $n + 1$ or earlier.

Since this is a synchronous system, these will be available
to $x$ at the latest in round $n + 2$. By the definition of the
convergecast algorithm it then computes the maximum over all received values and
sends the resulting value to $\prnt{x}$ in round $n + 2$.
\end{proof}

\begin{theorem}
In a synchronous distributed system with a given rooted spanning tree of depth $d$, the time
complexity of the convergecast algorithm is $d + 1$.
\end{theorem}

\begin{proof}
Convergecast terminates once $p_r$ has received a message from all of its children.
$\dpth{p_r} = d$ implies that the depth of all child nodes of $p_r$ must be
$\leq d - 1$, with equality holding for at least one child. By lemma \ref{lemma:1sync},
every child must have sent a message to $p_r$ at the latest by round $d$. In round
$d + 1$, $p_r$ has received a message from all child nodes and the algorithm terminates.
\end{proof}

\begin{lemma} \label{lemma:1async}
In an asynchronous distributed system with a given rooted spanning tree executing the convergecast
algorithm, every processor at depth $t$ sends a message to its parent by time $t$.
\end{lemma}

\begin{proof}
By induction. This lemma holds for $t = 0$ by the description of the algorithm,
since all leaf nodes $x$ send a message to $\prnt{x}$.

Assume the lemma holds for $t \leq n$, and consider an arbitrary node $x$ at depth
$n + 1$. By the definition of the depth function, all child nodes of $x$ must be at
a depth $\leq n$, and by the inductive hypothesis must have sent a message to
$x$ at time $n$ or earlier. 
The maximal message delay is normalized, therefore all messages sent at time $n$
must be processed by time $n + 1$.

This implies that $x$ must have received
a message from all children at time $n + 1$. By the definition of the
convergecast algorithm it then computes the maximum over all received values and
sends the resulting value to $\prnt{x}$ at time $n + 1$.
\end{proof}

\begin{theorem}
In an asynchronous distributed system with a given rooted spanning tree of depth $d$, the time
complexity of the convergecast algorithm is $d + 1$.
\end{theorem}

\begin{proof}
Convergecast terminates once $p_r$ has received a message from all of its children.
$\dpth{p_r} = d$ implies that the depth of all child nodes of $p_r$ must be
$\leq d - 1$, with equality holding for at least one child. By lemma \ref{lemma:1async},
every child must have sent a message to $p_r$ at the latest by time $d - 1$. At time
$d$, $p_r$ has received a message from all child nodes and the algorithm terminates.
\end{proof}

% ------------------------------------------------------------------------------

\begin{Exc}{(A2.3.v0, 9 points):}
Consider a synchronous distributed system of $n$ processors
$\Pi=\{p_0,\dots,p_{n-1}\}$, connected via a tree of depth $D\geq0$
rooted at processor $p_0$. For simplicity, assume that there is
one additional processor $p_{sink}$ above $p_0$, connected via a single link
$(p_0,p_{sink})$, which just consumes every message sent by $p_0$.
Assume that every processor $p_i\in\Pi$ has
some data $D_i^k$ available at the beginning of every round $k\geq 1$;
for simplicity, assume that $D_i^k$ is already available in the
computing step terminating the previous round $k-1$ (resp.\
in the initial configuration for $k=1$).

Solve the following tasks:
\begin{enumerate}
\item[(1)] Devise a distributed algorithm, which, for every $k\geq 1$,
lets $p_0$ send a single message $M^k$ containing the set
$\{D_i^k| i\in\Pi\}$ to $p_{sink}$ in
round $k+X$, for some fixed $X$ (that may depend on $D$, though).
If needed, you may assume that every processor $p_i$ knows its
height $h_i$ (= its level measured from the bottom leaves;
the height of a chain of $D$ processors is hence $D-1$, for example) in
the tree. Provide a sound proof that it indeed achieves its
goal.

\item[(2)] Assuming that every $D_i^k$ requires $B$ bits,
give the total bit
complexity (taken over all messages containing data relevant for
$M^k$) for generating $M^k$, and the local memory requirement
(without $\inbuf_i[*]$, $\outbuf_i[*]$ and round number) for $p_i$.
\end{enumerate}
\end{Exc}

\begin{algorithm}
\caption{Tree Pipeline} \label{alg:tpipe}
\begin{algorithmic}[1]
\Statex Code for processor $p_i, 0 \leq i \leq n - 1$
\Statex Initially, $h_i = i$'s height, $\text{parent}_i = i$'s parent,
       and msgs$_i = \{ D_i^1, D_i^2, \ldots \}$
\For{each round $t$}
    \State $\text{msgs}_i \gets \text{msgs}_i \cup \text{the set of all received messages}$

        \If{$k = t - h_i > 0$} \label{line:if}
        \State Remove all $D_*^k$ from $\text{msgs}_i$ and send them to parent \label{line:send}
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

Essentially, each node waits until it has all $D_*^k$ messages and
then forwards them to its parent, using $\text{msgs}_i$ as temporary storage.

\begin{lemma} \label{lem:tpipe}
At the beginning of round $k + D$, the root node $p_0$ of a tree of depth $D$
stores the set of all $D_*^k$ messages in $\text{msgs}_i \cup \text{inbuf}_i[\cdot]$.
\end{lemma}

\begin{proof}
Induction on the depth $D$.

The base case is a tree with $D = 0$. Since the tree consists only of a single node $p_0$,
$\text{msgs}_0$ is initialized to contain the set of all $D_0^*$, 
and messages $D_*^k$ are only removed in the corresponding round $k + D = k$, 
the complete set of $D_*^k$ messages is contained in 
$\text{msgs}_0 \cup \text{inbuf}_0[\cdot]$ at the beginning of round $k$.

We now assume that at the beginning of round $k + D'$, the root node $p_0$ of a 
tree of depth $D'$ stores the set of all $D_*^k$ messages in 
$\text{msgs}_i \cup \text{inbuf}_i[\cdot]$ for all depth $D' \leq D - 1$.
Consider a tree $T$ of depth $D$ and all subtrees $T'_i$ rooted at
the child nodes of $T$'s root node. It follows for every $T'_i$:

\begin{itemize}
\item The depth of $T'_i$ is $h_i \leq D - 1$.
\item By the induction hypothesis, in round $k + h_i$ the root node stores
      the complete set of $D_*^k$.
\item Inspecting the algorithm, we see in lines \ref{line:if} and \ref{line:send}
      that all $D_*^k$ are sent to the root's parent in round $k + h_i$.
\item These messages arrive at the subtree's root's parent in root $k + h_i + 1$.
\end{itemize}

Because $\forall i: h_i \leq D - 1$, they arrive at $p_0$ at 
$\max_i k + h_i + 1 \leq k + D$. Since messages are stored in $\text{msgs}_0$
upon arrival, and $D_*^k$ messages are removed only in round $k + D$,
$p_0$ must contain all $D_*^k$ in $\text{msgs}_0 \cup \text{inbuf}_0[\cdot]$.
\end{proof}

\begin{theorem}
$p_{sink}$ receives the set of all $D_*^k$ messages in round $k + D + 1$.
\end{theorem}

\begin{proof}
By lemma \ref{lem:tpipe}, $p_0$ has all $D_*^k$ messages at the beginning
of round $k + D$. By the code, these are sent to its parent $p_{sink}$ in the same
round, and arrive in round $k + D + 1$.
\end{proof}

Each message $D_i^k$ follows the unique path from $p_i$ to the root node $p_0$.
The longest such path is of length $D$, and $M^k$ consists of $n$ messages; therefore, the bit complexity is $O(DBn)$.

A node $p_i$ at height $h_i$ stores, in the worst case, the messages of itself and
all its descendants for up to $h_i + 1$ rounds. A local space complexity of
$O(nh_i)$ follows.

% ------------------------------------------------------------------------------

\begin{Exc}{(L.8.8.v0, 3 points):}
Characterize the (unique!) set of event traces $P$ that is both
a safety and a liveness property.
\end{Exc}


The set of all possible traces $P$ is both a safety and a liveness property:

\begin{itemize}
\item It is trivially non-empty,
\item and since it contains all possible traces, it is therefore
    \begin{itemize}
    \item prefix-closed,
    \item limit-closed,
    \item and every finite trace has an extension in $P$.
    \end{itemize}
\end{itemize}

% ------------------------------------------------------------------------------

\begin{Exc}{(W2.1.v0, 9 points):}
Consider a distributed system of $n$ processors, in a
connected (but not necessarily fully connected) network $G$.
Assume that every $p_i$ has
an array $\neighbors_i[*]$ that gives its neighbor processors,
sorted according to decreasing communication link quality.
For example, in a wireless setting, it could be sorted according
to increasing Euclidean distance between $p_i$ and its neighbors.
Let this quality of the communication link $(p_i,p_j)$ be
denoted as $|(p_i,p_j)|=|(p_j,p_i)|$, which we assume to be (slightly)
different from any other $|(p_x,p_y)|$ for simplicity, and let
the corresponding order $<_i$
of the neighbors of $p_i$ be defined as
$p_j=\neighbors_i[k] <_i p_\ell=\neighbors_i[m]$ iff $k<m$ (which
implies $|(p_i,p_j)|<|(p_i,p_\ell)|$).

Consider the following asynchronous distributed algorithm, which constructs
a less dense communication topology $T$ (not necessarily a spanning
tree like our Algorithm~2, but typically a fairly sparse graph):

\begin{code}%
\vspace*{-1cm}%
\emn{Code for processor $p_i$, $0\leq i \leq n-1$, with given
array $\neighbors_i[*]$}\NL
\emn{$T$ will consist of the edges $(p_i,p_j)$ with $p_j\in N_i$.}\NL
VAR $N_i := \emptyset$ // neighbors to be included\NL
\> $\overline{N}_i := \emptyset$ // neighbors to be excluded\\
\NL
for $k=1$ to $|\neighbors_i[*]|$ do // go over all neighbors\NL
\> $j := \neighbors_i[k]$\NL
\> send message "?" to $p_j$ // ask for $p_j$'s neighbors array\NL
\> receive array $\neighbors_j[*]$ from $p_j$\NL
\> if $\exists p_\ell \in N_i \cup \overline{N}_i$ with $p_\ell <_j p_i$\NL
\>\> $\overline{N}_i := \overline{N}_i \cup \{p_j\}$ // exclude $p_j$\NL
\> else\NL
\>\> $N_i := N_i \cup \{p_j\}$ // include $p_j$\\
\NL
On receiving "?" from $p_j$:\NL
\> send message containing $\neighbors_i[*]$ to $p_j$
\end{code}

Solve the following tasks:
\begin{enumerate}
\item[(1)] Provide the complete translation of this algorithm into the corresponding
transition relation + initial state. Recall that sequential computations can
usually be packed into in a single state transition.

\item[(2)] Prove that the algorithm always constructs $T$ consistently, in
the sense that $p_i$ includes $p_j$ in $N_i$ iff $p_j$ includes $p_i$
in $N_j$.

\item[(3)] For arbitrary (but different) choices of link quality
$|(p_i,p_j)|$, prove that $T$ is connected and that its shortest
cycle has length 4.
\footnote{Whereas this does not imply that $T$ is always sparse,
one could e.g.\ show that the maximum degree of every processor is at
most 6 when the link quality $|(p_i,p_j)|$ is the processors' Euclidean
distance and $G$ is such that if some link $(p_i,p_j)$ is
in $G$, then every shorter link $(p_i,p_\ell)$ with $|(p_i,p_\ell)|
\leq |(p_i,p_j)|$ is also in $G$.}
\end{enumerate}
\end{Exc}

% TODO: Assumption of n > 1, idle transition, 'sending to nonexistent
% neighbors', N' = N \union .. notation, don't use lexicographic
% order for compound transitions, define \Phi'.

The state machine description of the given algorithm is as follows:

Variables $\in L_i$ of processor $p_i$:
\begin{itemize}
\item $\text{neighbors}_i[\cdot], N_i, \overline{N}_i$: arrays of nodes
\end{itemize}

Initial state for all $i$:
\begin{itemize}
\item $\text{neighbors}_i[\cdot] = $ a list of all neighbors of $p_i$, sorted by their
      link quality in decreasing order
\item $N_i, \overline{N}_i = \emptyset$
\item $\text{inbuf}_i[\cdot] = \emptyset$
\item $\text{outbuf}_i[\cdot] = \emptyset$, except $\text{outbuf}_i[\text{neighbors}_i[1]] = \text{``?''}$
\end{itemize}

Elementary transitions for each $p_i$:
\begin{itemize}
\item \emph{Transition 1.j}. $\forall q_i \in Q_i: \text{``?''} \in \text{inbuf}_i[j]$.
      Then $(q_i, \phi_i, q'_i) \in \Phi_i$,
      where $q'_i = q_i$ except:
      \begin{itemize}
      \item $\text{outbuf}_i[j] = \text{outbuf}_i[j] \cup \{\text{neighbors}_i[\cdot]\}$
      \item $\text{inbuf}_i[j] = \text{inbuf}_i[j] \setminus \text{\{``?''\}}$
      \end{itemize}
\item \emph{Transition 2.j}. $\forall q_i \in Q_i: \text{an array neighbors}_j[\cdot] \in \text{inbuf}_i[j]$
      such that $j = \text{neighbors}_i[k]$,
      and $\exists p_{\ell} \in N_i \cup \overline{N}_i: p_{\ell} <_j p_i$.
      Then $(q_i, \phi_i, q'_i) \in \Phi_i$,
      where $q'_i = q_i$ except:
      \begin{itemize}
      \item $\overline{N}_i = \overline{N}_i \cup \{ p_j \}$
      \item $\text{inbuf}_i[j] = \text{inbuf}_i[j] \setminus \{\text{neighbors}_j[\cdot]\}$
      \item $\text{outbuf}_i[\text{neighbors}_i[k + 1]] = 
             \text{outbuf}_i[\text{neighbors}_i[k + 1]] \cup \text{\{``?''\}}$. (Sending
             to a nonexistent neighbor has no effect).
      \end{itemize}
\item \emph{Transition 3.j}. $\forall q_i \in Q_i: \text{an array neighbors}_j[\cdot] \in \text{inbuf}_i[j]$
      such that $j = \text{neighbors}_i[k]$,
      and $\nexists p_{\ell} \in N_i \cup \overline{N}_i: p_{\ell} <_j p_i$.
      Then $(q_i, \phi_i, q'_i) \in \Phi_i$,
      where $q'_i = q_i$ except:
      \begin{itemize}
      \item $N_i = N_i \cup \{ p_j \}$
      \item $\text{inbuf}_i[j] = \text{inbuf}_i[j] \setminus \{\text{neighbors}_j[\cdot]\}$
      \item $\text{outbuf}_i[\text{neighbors}_i[k + 1]] = 
             \text{outbuf}_i[\text{neighbors}_i[k + 1]] \cup \{\text{``?''}\}$. (Sending
             to a nonexistent neighbor has no effect).
      \end{itemize}
\end{itemize}

The set of compound transitions is formed by taking the transitive closure over all elementary
transitions while respecting lexicographic order on the transition labels (i.e. Transition $3.2$
must occur before $3.4$, and $2.5$ before $3.1$).

\begin{theorem} \label{thm:tconsistent}
The algorithm always constructs $T$ consistently, i.e. $\forall i, j$:
$p_i$ includes $p_j$ in $N_i$ iff $p_j$ includes $p_i$ in $N_j$.
\end{theorem}

\begin{proof}
We begin with initial observations:

\begin{enumerate}
\item The mutable local state consisting of $N_i$ and
$\overline{N}_i$ does not influence $p_j, i \neq j$.
\item Elements are never removed from the sets $N_i, \overline{N}_i$.
\item The sets $N_i, \overline{N}_i$ are disjunct.
\item All neighbors $p_j <_i p_k$ enter $N_i \cup \overline{N}_i$ before $p_k$.
\item The $<_i$ relation is static.
\end{enumerate}

Let $E = C^0, \phi^1, C^1, \ldots$ be an arbitrary execution, and let $p_i, p_j$ be neighbors
in the network $G$. Without loss of generality, let $p_i$ add $p_j$ to $N_i \cup \overline{N}_i$
in $E$ before $p_j$ adds $p_i$ to $N_j \cup \overline{N}_j$. 
Let $(C_{j-1}, \phi_j, C_j)$ be the step which processes
the $\text{neighbors}_i[\cdot]$ message at $p_j$, and let $(C_{i-1}, \phi_i, C_i)$
be the step in which the $\text{neighbors}_j[\cdot]$ message is processed at at $p_i$.
We now prove the theorem by
showing both $p_j \in N_i \rightarrow p_i \in N_j$ and $p_i \in N_j \rightarrow p_j \in N_i$.

Proof of $p_j \in N_i \rightarrow p_i \in N_j$: 
We examine $\phi_j$ under the assumption that $p_j \in N_i$ in $C_i$.
By contradiction, suppose that $\exists p_\ell \in N_j \cup \overline{N}_j: 
p_\ell <_i p_j$ (which would force $\phi_j$ to exclude $p_i$). 

\begin{align}
&\exists p_\ell \in N_j \cup \overline{N}_j: p_\ell <_i p_j \text{ in } C_{j-1} & \\
&p_\ell <_j p_i & \text{(1), since } p_\ell \in N_j \cup \overline{N}_j \\
&p_\ell \in N_i \cup \overline{N}_i \text{ in } C_{i-1} & \text{(1), since } p_\ell <_i p_j \\
&p_\ell \in N_i \cup \overline{N}_i: p_\ell <_j p_i \text{ in } C_{i-1} & \text{(2), (3)} \\
&p_j \in \overline{N}_i \text{ in } C_i & \text{(4), algorithm line 10} \\
&p_j \not\in N_i \text{ in } C_i & \text{(5), mutual exclusion of } N_i, \overline{N}_i
\end{align}
This contradicts the assumption, and therefore $\phi_j$ must add $p_i$ to $N_j$.

Proof of $p_i \in N_j \rightarrow p_j \in N_i$: Assume that $\phi_j$ adds
$p_i$ to $N_j$ and therefore $\nexists p_\ell \in N_j \cup \overline{N}_j: 
p_\ell <_i p_j$ in $C_{j-1}$. Suppose that $\phi_i$ excluded $p_j$, implying
$\exists p_\ell \in N_i \cup \overline{N}_i: p_\ell <_j p_i \text{ in } C_{i-1}$.
The contradiction follows by the same reasoning as in the other direction.

Hence, eventually $\forall i,j: p_i \in N_j \leftrightarrow p_j \in N_i$.
\end{proof}

\begin{theorem}
$T$ is connected.
\end{theorem}

\begin{proof}
By way of contradiction, assume that $T$ is not connected, i.e. it consists of 2
or more components. Fix any two such components $A, B$, and let $E$ be the list
of all edges between $A$ and $B$ in the original graph $G$. In particular, let
$e_0 = (p_i, p_j), p_i \in A, p_j \in B$ be the edge with minimal costs in $E$.
We now show that in every 
possible execution, $e_0$ must be placed included in $T$.

Consider the step $(C_{i-1}, \phi_i, C_i)$ in which $p_i$ processes the 
$\text{neighbors}_j[\cdot]$ message. Since $e_0$ has minimal cost over all edges
between $A$ and $B$ and edges are processed in order of increasing costs,
$N_i \cup \overline{N}_i$ does not contain any edges
leading to $B$ in $C_{i-1}$. Therefore, it is impossible for any edge in 
$N_i \cup \overline{N}_i$ to be closer to $p_j$ than $p_i$. Thus $p_j$
is included in line 12 of the algorithm.

By theorem \ref{thm:tconsistent}, $p_j$ must also include $p_i$ at some point
in the execution. We have therefore reached a contradiction since it has been
shown that it is impossible for $T$ to consist of more than one component.
\end{proof}

\begin{theorem}
The shortest cycle in $T$ has length $4$.
\end{theorem}

\begin{proof}
Going by the definition of cycle length as the number of distinct edges in a
cycle, lengths $< 1$ are impossible.

A cycle of length 1 is theoretically possible unless we require $G$ to be
without loops. So let us assume just that --- therefore no cycles of length
1 can exist since the algorithm does not add new edges.

A cycle of length 2 can only exist in a graph with multi-edges. 
Since in this problem, edges are defined by pairs of processors $(p_i, p_j)$,
it is impossible to specify more than one edge between a pair of processors.
Therefore, $T$ has no cycle of length 2.

We now consider cycles of length 3. We begin with a set of 3 (fully connected)
arbitrary processors
$p_i, p_j, p_k$, and show that it is impossible to construct a cycle between them.
W.l.o.g., let $p_i$ add $e_{ij}$ and $e_{ik}$ to $N_i$, and $e_{ij} <_i e_{ik}$.
By theorem \ref{thm:tconsistent} it follows that $e_{ij} \in N_j$ and $e_{ik}
\in N_k$. Note that $e_{ik} <_k e_{jk}$, otherwise $e_{ik}$ could not be added
to $N_i$. But then, $e_{jk}$ must be added to $\overline{N}_k$, since
by transitivity $e_{ij} <_j e_{jk}$.
\end{proof}

% Transitivity - not really. Expand on this.
